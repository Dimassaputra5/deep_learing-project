{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db038091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pytorch_optimizer as optim1\n",
    "\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import F1Score, MulticlassCohenKappa, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc788bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"synthetic_coffee_health_10000.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"uom190346a/global-coffee-health-dataset\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "df.set_index('ID', inplace=True)\n",
    "df.drop(columns=['Health_Issues'], inplace=True) \n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Sleep_Quality'], axis=1)\n",
    "y = df['Sleep_Quality']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat = X.select_dtypes(include=['object', 'category']).columns\n",
    "num, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    # ('poly', PolynomialFeatures(degree=1, include_bias=False)),\n",
    "    ('power', PowerTransformer(method='yeo-johnson')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipe, X_train.select_dtypes(include=['int64', 'float64']).columns),\n",
    "    ('cat', cat_pipe, X_train.select_dtypes(include=['object', 'category']).columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113daee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e8a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sleep_Quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f877fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = lambda s: {'Poor': 0, 'Fair':1, 'Good': 2, 'Excellent': 3}[s]\n",
    "y_train = y_train.map(map).values\n",
    "y_val = y_val.map(map).values\n",
    "y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314b1ef",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449fd2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d77b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, target = next(iter(train_loader))\n",
    "print(feature.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a8d28",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.Mish(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(16, 8),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(8, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.fc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLNN(LightningModule):\n",
    "    def __init__(self, input_size, num_classes=4, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() \n",
    "        self.model = NN(input_size=input_size, num_classes=num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_classes, weights='quadratic')\n",
    "        self.f1 = F1Score(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "        self.accurasy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs) \n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.accurasy(outputs, labels)\n",
    "        f1 = self.accurasy(outputs, labels)\n",
    "        kappa = self.accurasy(outputs, labels)\n",
    "\n",
    "        \n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_f1', f1, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_kappa', kappa, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.accurasy(outputs, labels)\n",
    "        f1 = self.accurasy(outputs, labels)\n",
    "        kappa = self.accurasy(outputs, labels)\n",
    "\n",
    "\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_f1', f1, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_kappa', kappa, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim1.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce438046",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886f880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    accelerator_type = 'gpu'\n",
    "    devices_to_use = 1\n",
    "else:\n",
    "    accelerator_type = 'cpu'\n",
    "    devices_to_use = 'auto'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    dirpath='checkpoints_SleepQuality/',\n",
    "    filename='bodyP-{epoch:02d}-{val_f1:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max'\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_f1',\n",
    "    patience=10,\n",
    "    mode='max'\n",
    ")\n",
    "lr_monitor_callback = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_monitor_callback],\n",
    "    logger=TensorBoardLogger(\"tb_logs_SleepQuality\", name=\"simple_model_experiment\"),\n",
    "    accelerator=accelerator_type,\n",
    "    devices=devices_to_use,\n",
    "    log_every_n_steps=10,\n",
    "    deterministic=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5d02b",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de807484",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PLNN(input_size=X_train.shape[1], num_classes=4, learning_rate=1e-3)\n",
    "trainer1.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f0c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9f24af",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9623e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer1.validate(model, val_loader, ckpt_path='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmsdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
